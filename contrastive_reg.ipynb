{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAdY3DB2gpVY"
      },
      "source": [
        "## Google colab setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "epTU0mbHgpVa"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IS_COLAB = True\n",
        "except:\n",
        "  IS_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoCoM19EgpVd",
        "outputId": "0f9dcb7a-c8c1-4395-a89b-5b9766b062c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "if IS_COLAB:\n",
        "  !pip install tensorflow_addons\n",
        "  !pip install unidecode\n",
        "  !pip install transformers\n",
        "  # !pip install nlpaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6QAQOrigpVf",
        "outputId": "2d7c78e3-cff6-4a08-baca-33adc0147b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "ZewVEh8GgpVf"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/SemiSupervised/*.csv ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELhYr27UgpVg"
      },
      "source": [
        "## Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "9RHrZPXIgpVg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from unidecode import unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "NNyA9_DfgpVi"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "tf.config.set_visible_devices(gpus[1], 'GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J10vZgj5gpVi"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "ATcVYFIzgpVj"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"train_ner.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "OY7jHZ-FgpVk"
      },
      "outputs": [],
      "source": [
        "def preprocess(x):\n",
        "    s = unidecode(x)\n",
        "    s = str.lower(s)\n",
        "    s = re.sub(r\"\\[[a-z]+\\]\",\"\", s)\n",
        "    s = re.sub(r\"\\*\",\"\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z0-9]+\",\" \",s)\n",
        "    s = re.sub(r\" +\",\" \",s)\n",
        "    s = re.sub(r\"(.)\\1+\",r\"\\1\",s)\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzuBpbLWgpVl",
        "outputId": "772b4513-a970-4aea-9444-8e3b1b99410b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ABUSE': 0, 'INSULT': 1, 'OTHER': 2, 'PROFANITY': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "label_ids = {label_name:i for i, label_name in enumerate(sorted(set(data[\"label\"])))}\n",
        "label_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "puCrlbe2gpVl",
        "outputId": "cc336f49-6bd8-4d96-8162-332ce4b61c36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text   label  \\\n",
              "0  32674  da de unde stii u mai [ORG] ca banii au fost p...   ABUSE   \n",
              "1  16514  m*uie [PERS] m*uie [PERS] ... m*uie\\nbai kakat...  INSULT   \n",
              "2  32556  PT ALA CARE ARE TREABA CU [PERS]!!ESTI UNUL CA...   OTHER   \n",
              "3  23861  sunt bucuros ca [PERS] nu a mai venit la [ORG]...   OTHER   \n",
              "4  21811  [PERS] esti....PE..N\\n ES..CU..LI..BI.L!!! te ...  INSULT   \n",
              "\n",
              "                                        preprocessed  \n",
              "0  da de unde sti u mai ca bani au fost pt si nu ...  \n",
              "1  muie muie muie bai kakatule stai in banca ta d...  \n",
              "2  pt ala care are treaba cu esti unul care nu ar...  \n",
              "3  sunt bucuros ca nu a mai venit la jucator de d...  \n",
              "4   esti pe n es cu li bi l te asemeni cu de la c...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4313eef-c92b-4a6c-adeb-c068d0b6b23f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocessed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32674</td>\n",
              "      <td>da de unde stii u mai [ORG] ca banii au fost p...</td>\n",
              "      <td>ABUSE</td>\n",
              "      <td>da de unde sti u mai ca bani au fost pt si nu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16514</td>\n",
              "      <td>m*uie [PERS] m*uie [PERS] ... m*uie\\nbai kakat...</td>\n",
              "      <td>INSULT</td>\n",
              "      <td>muie muie muie bai kakatule stai in banca ta d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32556</td>\n",
              "      <td>PT ALA CARE ARE TREABA CU [PERS]!!ESTI UNUL CA...</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>pt ala care are treaba cu esti unul care nu ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23861</td>\n",
              "      <td>sunt bucuros ca [PERS] nu a mai venit la [ORG]...</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>sunt bucuros ca nu a mai venit la jucator de d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21811</td>\n",
              "      <td>[PERS] esti....PE..N\\n ES..CU..LI..BI.L!!! te ...</td>\n",
              "      <td>INSULT</td>\n",
              "      <td>esti pe n es cu li bi l te asemeni cu de la c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4313eef-c92b-4a6c-adeb-c068d0b6b23f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4313eef-c92b-4a6c-adeb-c068d0b6b23f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4313eef-c92b-4a6c-adeb-c068d0b6b23f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data[\"preprocessed\"] = data[\"text\"].apply(preprocess)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OkPqrqdAgpVm",
        "outputId": "937749db-1cf9-408c-d323-ab6a24cea79d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text   label  \\\n",
              "0  32674  da de unde stii u mai [ORG] ca banii au fost p...   ABUSE   \n",
              "1  16514  m*uie [PERS] m*uie [PERS] ... m*uie\\nbai kakat...  INSULT   \n",
              "2  32556  PT ALA CARE ARE TREABA CU [PERS]!!ESTI UNUL CA...   OTHER   \n",
              "3  23861  sunt bucuros ca [PERS] nu a mai venit la [ORG]...   OTHER   \n",
              "4  21811  [PERS] esti....PE..N\\n ES..CU..LI..BI.L!!! te ...  INSULT   \n",
              "\n",
              "                                        preprocessed  class  \n",
              "0  da de unde sti u mai ca bani au fost pt si nu ...      0  \n",
              "1  muie muie muie bai kakatule stai in banca ta d...      1  \n",
              "2  pt ala care are treaba cu esti unul care nu ar...      2  \n",
              "3  sunt bucuros ca nu a mai venit la jucator de d...      2  \n",
              "4   esti pe n es cu li bi l te asemeni cu de la c...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e8ad65e-3cac-4cdf-89b1-af6861b701fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocessed</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32674</td>\n",
              "      <td>da de unde stii u mai [ORG] ca banii au fost p...</td>\n",
              "      <td>ABUSE</td>\n",
              "      <td>da de unde sti u mai ca bani au fost pt si nu ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16514</td>\n",
              "      <td>m*uie [PERS] m*uie [PERS] ... m*uie\\nbai kakat...</td>\n",
              "      <td>INSULT</td>\n",
              "      <td>muie muie muie bai kakatule stai in banca ta d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32556</td>\n",
              "      <td>PT ALA CARE ARE TREABA CU [PERS]!!ESTI UNUL CA...</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>pt ala care are treaba cu esti unul care nu ar...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23861</td>\n",
              "      <td>sunt bucuros ca [PERS] nu a mai venit la [ORG]...</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>sunt bucuros ca nu a mai venit la jucator de d...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21811</td>\n",
              "      <td>[PERS] esti....PE..N\\n ES..CU..LI..BI.L!!! te ...</td>\n",
              "      <td>INSULT</td>\n",
              "      <td>esti pe n es cu li bi l te asemeni cu de la c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e8ad65e-3cac-4cdf-89b1-af6861b701fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e8ad65e-3cac-4cdf-89b1-af6861b701fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e8ad65e-3cac-4cdf-89b1-af6861b701fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data[\"class\"] = data[\"label\"].map(lambda x: label_ids[x])\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vhnskykgpVm",
        "outputId": "99097769-aed0-42a9-b63d-04ff650b4dd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OTHER        3649\n",
              "ABUSE        2768\n",
              "INSULT       2242\n",
              "PROFANITY    1294\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCSuJiBzgpVn"
      },
      "source": [
        "## Prepare data splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "6teKcVuJgpVn"
      },
      "outputs": [],
      "source": [
        "tok_robert = AutoTokenizer.from_pretrained(\"readerbench/RoBERT-base\")\n",
        "robert = TFAutoModel.from_pretrained(\"readerbench/RoBERT-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "SGPTE7pOgpVo"
      },
      "outputs": [],
      "source": [
        "def split_ssl_data(ids_array,mask_array,labels,num_classes,label_percent):\n",
        "  labeled = None\n",
        "  unlabeled = None\n",
        "\n",
        "  for class_idx in range(num_classes):\n",
        "    class_ids = ids_array[labels==class_idx]\n",
        "    class_mask = mask_array[labels==class_idx]\n",
        "    sz = int(label_percent * class_ids.shape[0])\n",
        "\n",
        "    labels_reduced = labels[labels==class_idx][:sz]\n",
        "    labeled_ids, unlabeled_ids = class_ids[:sz], class_ids[sz:]\n",
        "    labeled_mask, unlabeled_mask = class_mask[:sz], class_mask[sz:]\n",
        "\n",
        "    if not labeled:\n",
        "      labeled = (labeled_ids, labeled_mask, labels_reduced)\n",
        "      unlabeled = (unlabeled_ids, unlabeled_mask)\n",
        "    else:\n",
        "      labeled = (\n",
        "          np.concatenate([labeled[0],labeled_ids]),\n",
        "          np.concatenate([labeled[1],labeled_mask]),\n",
        "          np.concatenate([labeled[2],labels_reduced])\n",
        "      )\n",
        "      unlabeled = (\n",
        "          np.concatenate([unlabeled[0],unlabeled_ids]),\n",
        "          np.concatenate([unlabeled[1],unlabeled_mask]),\n",
        "      )\n",
        "\n",
        "  return labeled, unlabeled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "13aGHiCOgpVo"
      },
      "outputs": [],
      "source": [
        "def preprocess_robert(x):\n",
        "  t = tok_robert(x,padding=\"max_length\",max_length=96,truncation=True,return_tensors='np')\n",
        "  return t[\"input_ids\"], t[\"attention_mask\"]\n",
        "\n",
        "def map_func(input_ids, masks, labels):\n",
        "  return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
        "\n",
        "def map_func2(input_ids, masks):\n",
        "  return {'input_ids': input_ids, 'attention_mask': masks}\n",
        "\n",
        "def prepare_ds(filename,batch_size=64):\n",
        "  df = pd.read_csv(filename)\n",
        "  X_id_mask = df['text'].map(preprocess).apply(preprocess_robert).apply(pd.Series)\n",
        "\n",
        "  X_id_mask.columns = [\"input_ids\",\"attention_mask\"]\n",
        "\n",
        "  ids_array = np.squeeze(np.stack(X_id_mask.input_ids.values), axis=1)\n",
        "  mask_array = np.squeeze(np.stack(X_id_mask.attention_mask.values), axis=1)\n",
        "  labels = df[\"label\"].map(lambda x: label_ids[x]).values\n",
        "\n",
        "  res_ds = tf.data.Dataset.from_tensor_slices((ids_array, mask_array, labels)).map(map_func).shuffle(len(df)).batch(batch_size)\n",
        "  return res_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "jMuXkEkDgpVp"
      },
      "outputs": [],
      "source": [
        "def prepare_train_ds(filename,batch_size=16,label_percent=0.2):\n",
        "  df = pd.read_csv(filename)\n",
        "  df = df.sample(frac=1)\n",
        "  X_id_mask = df['text'].map(preprocess).apply(preprocess_robert).apply(pd.Series)\n",
        "\n",
        "  X_id_mask.columns = [\"input_ids\",\"attention_mask\"]\n",
        "\n",
        "  ids_array = np.squeeze(np.stack(X_id_mask.input_ids.values), axis=1)\n",
        "  mask_array = np.squeeze(np.stack(X_id_mask.attention_mask.values), axis=1)\n",
        "  labels = df[\"label\"].map(lambda x: label_ids[x]).values\n",
        "\n",
        "  labeled, unlabeled = split_ssl_data(ids_array,mask_array,labels,len(label_ids),label_percent)\n",
        "  labeled_ds = tf.data.Dataset.from_tensor_slices(labeled)\n",
        "  labeled_ds = labeled_ds.map(map_func).shuffle(len(labeled_ds)).batch(batch_size).repeat()\n",
        "  unlabeled_ds = tf.data.Dataset.from_tensor_slices(unlabeled)\n",
        "  unlabeled_ds = unlabeled_ds.map(map_func2).shuffle(len(unlabeled_ds)).batch(batch_size).repeat()\n",
        "  \n",
        "  return labeled_ds, unlabeled_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "dTFlVZhygpVp"
      },
      "outputs": [],
      "source": [
        "labeled_ds, unlabeled_ds = prepare_train_ds(\"train_ner.csv\")\n",
        "test_ds = prepare_ds(\"test_ner.csv\")\n",
        "val_ds = prepare_ds(\"validation_internal_ner.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wWCe2qYgpVq"
      },
      "source": [
        "## Model definition and declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "KPWTrY-fgpVq"
      },
      "outputs": [],
      "source": [
        "class FixMatchCR(tf.keras.Model):\n",
        "  def __init__(self,bert_model,num_classes=4,**kwargs):\n",
        "    super(FixMatchCR,self).__init__(**kwargs)\n",
        "    self.bert = bert_model\n",
        "\n",
        "    self.num_classes = num_classes\n",
        "    self.weak_augment = tf.keras.layers.GaussianNoise(stddev=0.5)\n",
        "    self.strong_augment = tf.keras.layers.GaussianNoise(stddev=5)\n",
        "\n",
        "    self.cls_head = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(256,activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(64,activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(self.num_classes, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    ids, mask = inputs\n",
        "    \n",
        "    embeds = self.bert(input_ids=ids, attention_mask=mask,training=training).pooler_output\n",
        "\n",
        "    strongs = self.strong_augment(embeds,training=training)\n",
        "    weaks = self.weak_augment(embeds,training=training)\n",
        "\n",
        "    strong_preds = self.cls_head(strongs,training=training)\n",
        "    weak_preds = self.cls_head(weaks,training=training)\n",
        "\n",
        "    return weak_preds, strong_preds, strongs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proj_head = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(256,activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(256)\n",
        "])\n"
      ],
      "metadata": {
        "id": "hYtbpbsvkgl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "pfaURTnkgpVq"
      },
      "outputs": [],
      "source": [
        "model = FixMatchCR(bert_model=robert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKa3fRppgpVr"
      },
      "source": [
        "## Train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "bcxYDlq7gpVs"
      },
      "outputs": [],
      "source": [
        "optim = tfa.optimizers.AdamW(weight_decay=0.001,learning_rate=0.005)\n",
        "optim_proj = tfa.optimizers.AdamW(weight_decay=0.000,learning_rate=0.001)\n",
        "optim2 = tfa.optimizers.AdamW(weight_decay=0.0,learning_rate=0.00001)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "val_prec_metric = tf.keras.metrics.Precision(name=\"precision\")\n",
        "val_recall_metric = tf.keras.metrics.Recall(name=\"recall\")\n",
        "f1_metric_micro = tfa.metrics.F1Score(num_classes=4, threshold=0.5, average='micro', name='f1_micro')\n",
        "f1_metric_macro = tfa.metrics.F1Score(num_classes=4, threshold=0.5, average='macro', name='f1_macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "J2BnmBkggpVs"
      },
      "outputs": [],
      "source": [
        "thresh = 0.7\n",
        "thresh2 = 0.7\n",
        "tau = 1.0\n",
        "contrastive_weight = 1.0\n",
        "unsup_weight = 1.0\n",
        "num_classes=4\n",
        "steps_per_epoch = 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "yk65ez11gpVs"
      },
      "outputs": [],
      "source": [
        "# @tf.function\n",
        "# def train_step(x,y,xu):\n",
        "\n",
        "#   with tf.GradientTape() as tape:\n",
        "#       wl,_,_ = model([x[\"input_ids\"],x[\"attention_mask\"]],training=True)\n",
        "#       wu,su,sembeds = model([xu[\"input_ids\"],xu[\"attention_mask\"]],training=True)\n",
        "      \n",
        "#       zu = proj_head(sembeds, training=True)\n",
        "\n",
        "#       tu = tf.math.l2_normalize(zu,axis=1)\n",
        "\n",
        "#       pseudo_labels = tf.reduce_max(wu,axis=1)\n",
        "#       pseudo_idxs = tf.cast(tf.argmax(wu, axis=1),tf.int32)\n",
        "\n",
        "#       sims = tf.exp(tu @ tf.transpose(tu) / tau)\n",
        "#       cnt = sims.shape[0]\n",
        "#       sims = tf.linalg.set_diag(sims, tf.zeros(cnt))\n",
        "#       sums = tf.reshape(tf.reduce_sum(sims,axis=1),(-1,1))\n",
        "#       ss = sims/sums\n",
        "#       norm_sims = tf.where(tf.less(ss,1e-7), 1e-7,tf.math.log(ss))\n",
        "#       norm_sims = tf.where(tf.math.is_nan(norm_sims),1e-7,norm_sims)\n",
        "  \n",
        "#       prods = tf.linalg.set_diag(norm_sims, tf.zeros(cnt))\n",
        "\n",
        "#       a = tf.map_fn(lambda idx: tf.equal(pseudo_idxs,idx),tf.range(num_classes),fn_output_signature=bool)\n",
        "#       mask1 = tf.linalg.set_diag(tf.gather(a,pseudo_idxs),tf.zeros(cnt,dtype=bool))\n",
        "\n",
        "#       b = prods * tf.cast(mask1, tf.float32)\n",
        "\n",
        "#       p_cardinal = tf.cast(tf.math.count_nonzero(mask1, axis=1),tf.float32)\n",
        "      \n",
        "#       r = -tf.reduce_sum(b,axis=1)/p_cardinal\n",
        "#       r = tf.where(tf.math.is_nan(r),0.0,r)\n",
        "\n",
        "#       mask2 = pseudo_labels>thresh2\n",
        "\n",
        "#       lcr = tf.reduce_mean(r * tf.cast(mask2,float))\n",
        "      \n",
        "#       ls = loss_fn(y, wl)\n",
        "#       mask = pseudo_labels>thresh\n",
        "#       wu = wu[mask]\n",
        "#       su = su[mask]\n",
        "#       lu = loss_fn(tf.argmax(wu,axis=1),su)\n",
        "\n",
        "#       tf.print(ls, lu, lcr)\n",
        "#       tf.print(wl)\n",
        "\n",
        "#       loss = ls + unsup_weight * lu + contrastive_weight * lcr\n",
        "\n",
        "#   grads = tape.gradient(loss, [model.cls_head.trainable_weights, model.bert.trainable_weights, proj_head.trainable_weights])\n",
        "#   tf.print(grads)\n",
        "#   optim.apply_gradients(zip(grads[0], model.cls_head.trainable_weights))\n",
        "#   optim2.apply_gradients(zip(grads[1], model.bert.trainable_weights))\n",
        "#   optim_proj.apply_gradients(zip(grads[2], proj_head.trainable_weights))\n",
        "\n",
        "#   return loss\n",
        "\n",
        "@tf.function\n",
        "def train_step(x,y,xu):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "      wl,_,_ = model([x[\"input_ids\"],x[\"attention_mask\"]],training=True)\n",
        "      wu,su,sembeds = model([xu[\"input_ids\"],xu[\"attention_mask\"]],training=True)\n",
        "      \n",
        "      zu = proj_head(sembeds, training=True)\n",
        "\n",
        "      tu = tf.math.l2_normalize(zu,axis=1)\n",
        "\n",
        "      cnt = tf.shape(wu)[0]\n",
        "      pseudo_labels = tf.reduce_max(wu,axis=1)\n",
        "      pseudo_idxs = tf.argmax(wu, axis=1)\n",
        "      mask_labels = tf.cast(tf.equal(pseudo_idxs[:,tf.newaxis], pseudo_idxs[tf.newaxis,:]),tf.float32)\n",
        "\n",
        "      sims = tf.exp(tu @ tf.transpose(tu) / tau)\n",
        "      mask_self = tf.linalg.set_diag(tf.ones((cnt,cnt)),tf.zeros(cnt))\n",
        "      sims = sims * mask_self\n",
        "      sums = tf.reduce_sum(sims,axis=1,keepdims=True)\n",
        "      sims = sims/sums\n",
        "      sims = sims * mask_labels\n",
        "      counts = tf.math.count_nonzero(sims, axis=1)\n",
        "      mask_not_all_zero = counts > 0\n",
        "      sims = sims[mask_not_all_zero]\n",
        "      counts = tf.cast(counts[mask_not_all_zero],tf.float32)\n",
        "      sims = tf.where(tf.equal(sims,0.0),1.0,sims)\n",
        "      ru = -tf.reduce_sum(tf.math.log(sims),axis=1)/counts\n",
        "\n",
        "      mask2 = pseudo_labels[mask_not_all_zero] > thresh2\n",
        "      lcr = 0.0\n",
        "      ru = ru[mask2]\n",
        "      if tf.shape(ru)[0] != 0:\n",
        "        lcr = tf.reduce_mean(ru[mask2])\n",
        "\n",
        "      \n",
        "      ls = loss_fn(y, wl)\n",
        "      mask = pseudo_labels>thresh\n",
        "      wu = wu[mask]\n",
        "      su = su[mask]\n",
        "      lu = loss_fn(tf.argmax(wu,axis=1),su)\n",
        "\n",
        "      loss = ls + unsup_weight * lu + contrastive_weight * lcr\n",
        "\n",
        "  grads = tape.gradient(loss, [model.cls_head.trainable_weights, model.bert.trainable_weights, proj_head.trainable_weights])\n",
        "  optim.apply_gradients(zip(grads[0], model.cls_head.trainable_weights))\n",
        "  optim2.apply_gradients(zip(grads[1], model.bert.trainable_weights))\n",
        "  optim_proj.apply_gradients(zip(grads[2], proj_head.trainable_weights))\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    wpred,_,_ = model([x[\"input_ids\"],x[\"attention_mask\"]], training=False)\n",
        "    val_acc_metric.update_state(y, wpred)\n",
        "    true_hot = tf.one_hot(y, 4)\n",
        "    val_prec_metric.update_state(true_hot, wpred)\n",
        "    val_recall_metric.update_state(true_hot, wpred)\n",
        "    f1_metric_micro.update_state(true_hot, wpred)\n",
        "    f1_metric_macro.update_state(true_hot, wpred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnI1Wj_RgpVs",
        "outputId": "4075b949-8632-4a39-d4e5-1c2d0a9f92d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Training loss (for one batch) at step 0: 1.6571\n",
            "Training loss (for one batch) at step 100: 2.4492\n",
            "Training loss (for one batch) at step 200: 3.4256\n",
            "Training loss (for one batch) at step 300: 5.6411\n",
            "Validation acc: 0.562 precision: 0.716 recall: 0.291 f1_micro: 0.414 f1_macro: 0.189\n",
            "Time taken: 301.48s\n",
            "Epoch 1\n",
            "Training loss (for one batch) at step 0: 1.5789\n",
            "Training loss (for one batch) at step 100: 1.7030\n",
            "Training loss (for one batch) at step 200: 1.6334\n",
            "Training loss (for one batch) at step 300: 1.7024\n",
            "Validation acc: 0.664 precision: 0.691 recall: 0.625 f1_micro: 0.657 f1_macro: 0.563\n",
            "Time taken: 270.70s\n",
            "Epoch 2\n",
            "Training loss (for one batch) at step 0: 2.8119\n",
            "Training loss (for one batch) at step 100: 1.5986\n",
            "Training loss (for one batch) at step 200: 3.4101\n",
            "Training loss (for one batch) at step 300: 2.3705\n",
            "Validation acc: 0.741 precision: 0.747 recall: 0.736 f1_micro: 0.741 f1_macro: 0.720\n",
            "Time taken: 257.61s\n",
            "Epoch 3\n",
            "Training loss (for one batch) at step 0: 2.5561\n",
            "Training loss (for one batch) at step 100: 2.3910\n",
            "Training loss (for one batch) at step 200: 2.1733\n",
            "Training loss (for one batch) at step 300: 2.3997\n",
            "Validation acc: 0.752 precision: 0.765 recall: 0.745 f1_micro: 0.755 f1_macro: 0.738\n",
            "Time taken: 257.55s\n",
            "Epoch 4\n",
            "Training loss (for one batch) at step 0: 2.9717\n",
            "Training loss (for one batch) at step 100: 2.4322\n",
            "Training loss (for one batch) at step 200: 1.9534\n",
            "Training loss (for one batch) at step 300: 2.4204\n",
            "Validation acc: 0.772 precision: 0.778 recall: 0.771 f1_micro: 0.774 f1_macro: 0.764\n",
            "Time taken: 265.27s\n",
            "Restoring best weights relative to validation accuracy...\n"
          ]
        }
      ],
      "source": [
        "EPOCHS=5\n",
        "max_val_acc = 0.0\n",
        "best_weights = None\n",
        "\n",
        "l_iter = iter(labeled_ds)\n",
        "u_iter = iter(unlabeled_ds)\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f\"Epoch {epoch}\")\n",
        "  start_time = time.time()\n",
        "  for step in range(steps_per_epoch):\n",
        "    x, y = next(l_iter)\n",
        "    xu = next(u_iter)\n",
        "    \n",
        "    loss = train_step(x,y,xu)\n",
        "    if step % 100 == 0:\n",
        "      print(\n",
        "        \"Training loss (for one batch) at step %d: %.4f\"\n",
        "        % (step, float(loss))\n",
        "      )\n",
        "  for x_batch_val, y_batch_val in val_ds:\n",
        "      test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "  acc = float(val_acc_metric.result())\n",
        "  prec = float(val_prec_metric.result())\n",
        "  recall = float(val_recall_metric.result())\n",
        "  micro = float(f1_metric_micro.result())\n",
        "  macro = float(f1_metric_macro.result())\n",
        "\n",
        "  val_acc_metric.reset_states()\n",
        "  val_prec_metric.reset_states()\n",
        "  val_recall_metric.reset_states()\n",
        "  f1_metric_micro.reset_states()\n",
        "  f1_metric_macro.reset_states()\n",
        "\n",
        "  if acc > max_val_acc:\n",
        "    max_val_acc = acc\n",
        "    best_weights = model.get_weights()\n",
        "  print(f\"Validation acc: {acc:.3f} precision: {prec:.3f} recall: {recall:.3f} f1_micro: {micro:.3f} f1_macro: {macro:.3f}\")\n",
        "  print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "print(\"Restoring best weights relative to validation accuracy...\")\n",
        "model.set_weights(best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "CCg9eBFXgpVt",
        "outputId": "10db87be-1eef-422e-989a-5277016ebf8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc: 0.758 precision: 0.764 recall: 0.753 f1_micro: 0.758 f1_macro: 0.745\n"
          ]
        }
      ],
      "source": [
        "for x_batch_val, y_batch_val in test_ds:\n",
        "    test_step(x_batch_val, y_batch_val)\n",
        "acc = float(val_acc_metric.result())\n",
        "prec = float(val_prec_metric.result())\n",
        "recall = float(val_recall_metric.result())\n",
        "micro = float(f1_metric_micro.result())\n",
        "macro = float(f1_metric_macro.result())\n",
        "\n",
        "val_acc_metric.reset_states()\n",
        "val_prec_metric.reset_states()\n",
        "val_recall_metric.reset_states()\n",
        "f1_metric_micro.reset_states()\n",
        "f1_metric_macro.reset_states()\n",
        "print(f\"Test acc: {acc:.3f} precision: {prec:.3f} recall: {recall:.3f} f1_micro: {micro:.3f} f1_macro: {macro:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "ZZ1xeRz2gpVt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}